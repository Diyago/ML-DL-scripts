{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46f17064",
      "metadata": {
        "id": "46f17064"
      },
      "source": [
        "# 3. *Code*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c21fafa",
      "metadata": {
        "id": "7c21fafa"
      },
      "source": [
        "## 3.1 Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0b83137c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b83137c",
        "outputId": "4925d0f6-64b6-4ef1-a5f6-8768cea81acb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import gensim.downloader as api\n",
        "# and some other your dependencies\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import spacy  # For preprocessing\n",
        "import nltk\n",
        "import re\n",
        "from scipy.spatial.distance import cosine\n",
        "from tqdm import tqdm\n",
        "from nltk import word_tokenize, PorterStemmer\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf6551c",
      "metadata": {
        "id": "eaf6551c"
      },
      "source": [
        "## 3.2 Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c73eb32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c73eb32",
        "outputId": "69fb8822-c8f6-4e23-e5ad-22b0bebaf4f7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-22 17:56:34--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1 [following]\n",
            "--2024-09-22 17:56:34--  https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com/cd/0/inline/CbG86bWTGuTjwYPSoft_u9rwGf3KxndidKFMlGzAx-jSRcNDdnhGvTJbEazfzRzWlIWY0Llt0wcEDr3Y59cL6d_Kl6yDbcWMX42JlpfbBU-jYkg3uEpRCjCdAEOBfJ1a4r4/file?dl=1# [following]\n",
            "--2024-09-22 17:56:35--  https://uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com/cd/0/inline/CbG86bWTGuTjwYPSoft_u9rwGf3KxndidKFMlGzAx-jSRcNDdnhGvTJbEazfzRzWlIWY0Llt0wcEDr3Y59cL6d_Kl6yDbcWMX42JlpfbBU-jYkg3uEpRCjCdAEOBfJ1a4r4/file?dl=1\n",
            "Resolving uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com (uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com (uc900ac9904c0ede68ce3e711986.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  54.5MB/s    in 0.6s    \n",
            "\n",
            "2024-09-22 17:56:36 (54.5 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the data:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw\n",
        "\n",
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcefbcb3",
      "metadata": {
        "id": "bcefbcb3"
      },
      "source": [
        "### 3.1.1 Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b080556",
      "metadata": {
        "id": "0b080556"
      },
      "outputs": [],
      "source": [
        "def preprocess_phrase(phrase):\n",
        "    \"\"\"Preprocesses a phrase by converting to lowercase, removing punctuation,\n",
        "    tokenizing, and stemming.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase and remove punctuation\n",
        "    phrase = phrase.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize and stem\n",
        "    tokens = word_tokenize(phrase)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    return stemmed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dzdFa8ZlgWOU",
      "metadata": {
        "id": "dzdFa8ZlgWOU"
      },
      "outputs": [],
      "source": [
        "filteted_data = [preprocess_phrase(row) for row in data]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a62af06",
      "metadata": {
        "id": "5a62af06"
      },
      "source": [
        "## 3.3. Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TPEUShA4sPS3",
      "metadata": {
        "id": "TPEUShA4sPS3"
      },
      "source": [
        "### 3.3.1 Эмбединги\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f9699b0a",
      "metadata": {
        "id": "f9699b0a"
      },
      "outputs": [],
      "source": [
        "#Fit TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit([' '.join(phrase) for phrase in filteted_data])\n",
        "\n",
        "def get_phrase_embedding(phrase, preprose=False):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings.\n",
        "    \"\"\"\n",
        "    if preprose:\n",
        "      phrase = preprocess_phrase(phrase)\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "    word_vectors = []\n",
        "    tfidf_values = []\n",
        "\n",
        "    # Get TF-IDF values for the phrase, handling potential KeyError\n",
        "    tfidf = vectorizer.transform([' '.join(phrase)])\n",
        "\n",
        "    for word in phrase:\n",
        "      if word in model.key_to_index and word in vectorizer.vocabulary_:\n",
        "        word_vectors.append(model.get_vector(word))\n",
        "        tfidf_values.append(tfidf[0, vectorizer.vocabulary_[word]])\n",
        "\n",
        "    if word_vectors:\n",
        "      word_vectors = np.array(word_vectors)\n",
        "      tfidf_values = np.array(tfidf_values)\n",
        "      vector = np.average(word_vectors, axis=0, weights=tfidf_values)\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d5dfdfb9",
      "metadata": {
        "id": "d5dfdfb9"
      },
      "outputs": [],
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "model = api.load('glove-twitter-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1a9ae791",
      "metadata": {
        "id": "1a9ae791"
      },
      "outputs": [],
      "source": [
        "# compute vector embedding for all lines in data\n",
        "data_vectors = np.array([get_phrase_embedding(row) for row in filteted_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P1dL8jursW_e",
      "metadata": {
        "id": "P1dL8jursW_e"
      },
      "source": [
        "### 3.3.2 Xgbranker\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "SX6VPpKPshaI",
      "metadata": {
        "id": "SX6VPpKPshaI"
      },
      "outputs": [],
      "source": [
        "def is_exact_match(query, candidate):\n",
        "    # Ensure both inputs are strings\n",
        "    query_str = str(query)\n",
        "    candidate_str = str(candidate)\n",
        "\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    query_clean = query_str.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    candidate_clean = candidate_str.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "\n",
        "    # Return True if the cleaned strings are exactly the same\n",
        "    return query_clean == candidate_clean\n",
        "\n",
        "def simple_text_features(query, candidate):\n",
        "    # Ensure both inputs are strings\n",
        "    query_str = str(query)\n",
        "    candidate_str = str(candidate)\n",
        "\n",
        "    # Remove punctuation\n",
        "    query_clean = query_str.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    candidate_clean = candidate_str.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "\n",
        "    # Tokenize sentences into words\n",
        "    query_words = set(query_clean.split())\n",
        "    candidate_words = set(candidate_clean.split())\n",
        "\n",
        "    # Common characters\n",
        "    common_chars = len(set(query_clean) & set(candidate_clean))\n",
        "\n",
        "    # Common words\n",
        "    common_words = len(query_words & candidate_words)\n",
        "\n",
        "    # Length of each sentence (number of characters)\n",
        "    len_query = len(query_clean)\n",
        "    len_candidate = len(candidate_clean)\n",
        "\n",
        "    # Length of each sentence (number of words)\n",
        "    len_query_words = len(query_words)\n",
        "    len_candidate_words = len(candidate_words)\n",
        "\n",
        "    # Absolute difference in length of the sentences (character length)\n",
        "    length_diff = abs(len_query - len_candidate)\n",
        "\n",
        "    # Character overlap ratio\n",
        "    char_overlap_ratio = common_chars / min(len_query, len_candidate) if min(len_query, len_candidate) > 0 else 0\n",
        "\n",
        "    # Word overlap ratio\n",
        "    word_overlap_ratio = common_words / min(len_query_words, len_candidate_words) if min(len_query_words, len_candidate_words) > 0 else 0\n",
        "\n",
        "    # Jaccard similarity for word sets\n",
        "    jaccard_sim = common_words / len(query_words | candidate_words) if len(query_words | candidate_words) > 0 else 0\n",
        "\n",
        "    # Compile features into a dictionary\n",
        "    features = {\n",
        "        'common_chars': common_chars,\n",
        "        'common_words': common_words,\n",
        "        'len_query': len_query,\n",
        "        'len_candidate': len_candidate,\n",
        "        'length_diff': length_diff,\n",
        "        'char_overlap_ratio': char_overlap_ratio,\n",
        "        'word_overlap_ratio': word_overlap_ratio,\n",
        "        'jaccard_similarity': jaccard_sim\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def create_ranking_dataset(queries, candidate_questions):\n",
        "    data = []\n",
        "\n",
        "    # Iterate over queries\n",
        "    for i, query in enumerate(queries):\n",
        "        candidates = candidate_questions[i]\n",
        "\n",
        "        for j, candidate in enumerate(candidates):\n",
        "            # Check if exact match\n",
        "            if is_exact_match(query, candidate):\n",
        "                target = 1\n",
        "            else:\n",
        "                target = 0\n",
        "\n",
        "            # Assuming you have embeddings for both questions\n",
        "            query_embedding = data_vectors[i]\n",
        "            candidate_embedding = data_vectors[j]\n",
        "\n",
        "            # Example: Add cosine similarity as a feature\n",
        "            cosine_sim = cosine(query_embedding, candidate_embedding)\n",
        "            txt_features = simple_text_features(query, candidate)\n",
        "            feats = {\n",
        "                'query': query,\n",
        "                'candidate': candidate,\n",
        "                'cosine_sim': cosine_sim,\n",
        "                'target': target\n",
        "            }\n",
        "            feats.update(txt_features)\n",
        "            data.append(feats)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def rank_candidates(model, query, candidates):\n",
        "    data = []\n",
        "\n",
        "    for candidate in candidates:\n",
        "        query_embedding = get_phrase_embedding(query)\n",
        "        candidate_embedding = get_phrase_embedding(candidate)\n",
        "        cosine_sim = cosine(query_embedding, candidate_embedding)\n",
        "        txt_features = simple_text_features(query, candidate)\n",
        "        feats = {'cosine_sim': cosine_sim}\n",
        "        feats.update(txt_features)\n",
        "        data.append(feats)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Predict ranking scores\n",
        "    X = df.values\n",
        "    dtest = xgb.DMatrix(X)\n",
        "    scores = model.predict(dtest)\n",
        "\n",
        "    # Sort candidates by scores (higher is better)\n",
        "    sorted_candidates = [c for _, c in sorted(zip(scores, candidates), reverse=True)]\n",
        "\n",
        "    return sorted_candidates\n",
        "\n",
        "\n",
        "def prepare_data_for_xgb(df):\n",
        "    # Features and target\n",
        "    X = df.drop(['query', 'candidate', 'target'], axis=1).values\n",
        "    y = df['target'].values\n",
        "\n",
        "    # Grouping by query for ranking\n",
        "    group_sizes = df.groupby('query').size().values\n",
        "\n",
        "    return X, y, group_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "l1gripLqs7fE",
      "metadata": {
        "id": "l1gripLqs7fE"
      },
      "outputs": [],
      "source": [
        "df_data = pd.DataFrame(data)\n",
        "\n",
        "df = create_ranking_dataset(queries=df_data,\n",
        "                            candidate_questions=df_data)\n",
        "X, y, group_sizes = prepare_data_for_xgb(df)\n",
        "\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "dtrain.set_group(group_sizes)\n",
        "\n",
        "params = {\n",
        "    'objective': 'rank:pairwise',  # Ranking objective\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 4,\n",
        "    'eval_metric': 'ndcg',\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model_xgb = xgb.train(params, dtrain, num_boost_round=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "aa3cfdde",
      "metadata": {
        "id": "aa3cfdde"
      },
      "outputs": [],
      "source": [
        "def find_nearest(query, k=10):\n",
        "    \"\"\"\n",
        "    given text line (query), return k most similar lines from data, sorted from most to least similar\n",
        "    similarity should be measured as cosine between query and line embedding vectors\n",
        "    hint: it's okay to use global variables: data and data_vectors. see also: np.argpartition, np.argsort\n",
        "    \"\"\"\n",
        "    emb = get_phrase_embedding(query)\n",
        "    similarities = np.dot(data_vectors, emb) / (np.linalg.norm(data_vectors, axis=1) * np.linalg.norm(emb))\n",
        "\n",
        "\n",
        "    indices = np.argpartition(-similarities, k)[:k]\n",
        "\n",
        "    return [data[ind] for ind in indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LNi-_MyjzjTP",
      "metadata": {
        "id": "LNi-_MyjzjTP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be1ced65",
      "metadata": {
        "id": "be1ced65"
      },
      "source": [
        "## 3.4. Применение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5333929b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5333929b",
        "outputId": "4fea456b-b19f-40ae-f591-3c8a4d9a5b7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Based on his personality what country would you say Donald Trump was from if Donald Trump were not American?\\n',\n",
              " 'Who would be better for India, Donald Trump or Hillary Clinton?\\n',\n",
              " \"What will be Donald Trump's legacy?\\n\",\n",
              " 'What does Donald Trump think of India?\\n',\n",
              " 'What India thinks about Donald Trump?\\n',\n",
              " \"Why did Hillary Clinton go to Donald Trump's wedding in 2005, if Trump is a longtime racist and sexist?\\n\",\n",
              " 'Who would be a better president: Hillary Clinton or Donald Trump?\\n',\n",
              " 'Who will win, Donald Trump or Hillary Clinton?\\n',\n",
              " 'Who will win Hillary Clinton Or Donald Trump?\\n',\n",
              " 'Who will own the Trump brand after Trump takes office?\\n']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search = preprocess_phrase(\"Who is trump?\")\n",
        "top = 10\n",
        "pre_top = find_nearest(query=search, k=top*5)\n",
        "result = pre_top[0:top//2]\n",
        "xgb_output = rank_candidates(model_xgb, search, pre_top[len(result):])\n",
        "result + xgb_output[:(top-len(result))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gsi-Typ-6NSR",
      "metadata": {
        "id": "Gsi-Typ-6NSR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
